# -*- coding=utf-8 -*-
import os, sys, argparse, threading, subprocess, json, re, linecache
import juliet_parser as Juliet_parser
from xml.etree import ElementTree as ET
from ast_parser import ASTStats
from fcg import FCG
from glo import Global
from glo import Config
from dao import DBUtil

def divide(listTemp, n):
    for i in range(0, len(listTemp), n):
        yield listTemp[i:i + n]

class Util():
    
    def __init__(self):
        self.dao = DBUtil()
        self.stats = ASTStats()
        self.fcg = FCG()
        self.vuls = None
        self.testsuite = "" # testsuite name

    def copy(self, indir=None, outdir=None, testsuite='', cwe_list=[]):
        if indir == None or outdir == None:
            print("Error, neither indir nor outdir can be None")
            return
        self.testsuite = testsuite
        indir = os.path.abspath(indir)
        outdir = os.path.abspath(outdir)
        if testsuite == 'sard100' or testsuite == 'sard101':
            for f in os.listdir(indir):
                if f.startswith('manifest') and f.endswith('.xml'):
                    f = os.path.join(indir, f)
                    self.vuls = self.__parseSARD100Manifest(f, testsuite)
        elif testsuite == 'sard88':
            for f in os.listdir(indir):
                if f.startswith('manifest') and f.endswith('.xml'):
                    f = os.path.join(indir, f)
                    self.vuls = self.__parseSARD88Manifest(f, testsuite)
        elif testsuite == 'juliet':
            for f in os.listdir(indir):
                if f.startswith('manifest') and f.endswith('.xml'):
                    f = os.path.join(indir, f)
                    self.vuls = self.__parseJulietManifest(f, cwe_list_filter=cwe_list)
        # copy source files of juliet testcases into outdir
        if testsuite == 'juliet':
            Juliet_parser.create_single_testcase(indir, outdir, cwe_list=cwe_list)
        # copy source files of sard testsuites
        vuls = self.vuls
        for i in range(len(vuls)):
            _id = vuls[i][Global.KEY_TESTCASE_ID]
            testcase_outpath, testcase_origpath = '', ''
            if testsuite == 'sard100' or testsuite == 'sard101' or testsuite == 'sard88':
                __id = _id.split('_')[-1]
                testcase_origpath = os.path.join(indir, 'testcases/000/')
                testcase_origpath = os.path.join(testcase_origpath, __id[:3])
                testcase_origpath = os.path.join(testcase_origpath, __id[3:])
                testcase_outpath = os.path.join(outdir, _id)
                for parent, dirnames, filenames in os.walk(testcase_origpath):
                    for f in filenames:
                        abspath = os.path.join(parent, f)
                        relpath = abspath.split(testcase_origpath)[-1]
                        if relpath.startswith('/'):
                            relpath = relpath[1:]
                        outfile = os.path.join(testcase_outpath, relpath)
                        outfile_d = os.path.dirname(outfile)
                        if not os.path.exists(outfile_d):
                            os.makedirs(outfile_d)
                        os.system('cp %s %s'%(abspath, outfile))

    # copy proj from indir to outdir
    def copyAndParse(self, indir=None, outdir=None, testsuite='', cwe_list=[], parser='pycparser'):
        if indir == None or outdir == None:
            print("Error, neither indir nor outdir can be None")
            return
        self.testsuite = testsuite
        indir = os.path.abspath(indir)
        outdir = os.path.abspath(outdir)
        ########################################################
        # parse manifest.xml and write the info into self.vuls #
        ########################################################
        if testsuite == 'sard100' or testsuite == 'sard101':
            for f in os.listdir(indir):
                if f.startswith('manifest') and f.endswith('.xml'):
                    f = os.path.join(indir, f)
                    self.vuls = self.__parseSARD100Manifest(f, testsuite)
        elif testsuite == 'sard88':
            for f in os.listdir(indir):
                if f.startswith('manifest') and f.endswith('.xml'):
                    f = os.path.join(indir, f)
                    self.vuls = self.__parseSARD88Manifest2(f, testsuite)
        elif testsuite == 'juliet':
            for f in os.listdir(indir):
                if f.startswith('manifest') and f.endswith('.xml'):
                    f = os.path.join(indir, f)
                    self.vuls = self.__parseJulietManifest(f, cwe_list_filter=cwe_list)

        ###############################################
        # count loc, count function number, parse AST #
        ###############################################
        # copy source files of juliet testcases into outdir
        if testsuite == 'juliet':
            Juliet_parser.create_single_testcase(indir, outdir, cwe_list=cwe_list)

        # 把漏洞分成多个组，每组100个，防止所有漏洞过多而引起内存OOM或者数据库IO错误
        divided_vuls = divide(self.vuls, 1)
        print("%d vuls has been divided into %d groups" %(len(self.vuls), len(self.vuls)/100))

        final_vuls = [] # 存储所有漏洞

        for vuls_iter in divided_vuls:
            vuls = []  # 在这个循环中存储所有漏洞
            for one in vuls_iter:
                vuls.append(one)
            add_vuls = [] # add_vuls store counterexamples of juliet
            for i in range(len(vuls)):
                _id = vuls[i][Global.KEY_TESTCASE_ID]
                testcase_outpath, testcase_origpath = '', ''
                # copy source files of SARD100&SARD101 into outdir
                if testsuite == 'sard100' or testsuite == 'sard101' or testsuite == 'sard88':
                    __id = _id.split('_')[-1]
                    testcase_origpath = os.path.join(indir, 'testcases/000/')
                    testcase_origpath = os.path.join(testcase_origpath, __id[:3])
                    testcase_origpath = os.path.join(testcase_origpath, __id[3:])
                    testcase_outpath = os.path.join(outdir, _id)
                    for parent, dirnames, filenames in os.walk(testcase_origpath):
                        for f in filenames:
                            abspath = os.path.join(parent, f)
                            relpath = abspath.split(testcase_origpath)[-1]
                            if relpath.startswith('/'):
                                relpath = relpath[1:]
                            outfile = os.path.join(testcase_outpath, relpath)
                            outfile_d = os.path.dirname(outfile)
                            if not os.path.exists(outfile_d):
                                os.makedirs(outfile_d)
                            os.system('cp %s %s'%(abspath, outfile))

                if testsuite == 'juliet':
                    testcase_outpath = os.path.join(outdir, _id.split('__')[0])
                    testcase_outpath = os.path.join(testcase_outpath, _id)
                    if not os.path.exists(testcase_outpath):
                        continue
                

                # store the location of testcase
                vuls[i][Global.KEY_TESTCASE_DIR] = testcase_outpath
                # call cloc, get global lines of code & number of files
                file_num, loc = self.getLoc(testcase_outpath)
                vuls[i][Global.KEY_LOC] = loc
                vuls[i][Global.KEY_FILE_NUM] = file_num
                # get number of functions
                func_num, file_func_map = self.countFuncnum2(testcase_outpath)
                if testsuite == 'juliet':
                    func_num = 0
                    for f in file_func_map.keys():
                        if os.path.basename(f) in Global.JULIET_TESTCASESUPPORT:
                            continue
                        else:
                            func_num = func_num + len(file_func_map[f])
                vuls[i][Global.KEY_FUNC_NUM] = func_num

                # parse FCG
                self.fcg.setProj(testcase_outpath)
                self.fcg.gen_fcg()
                path = self.fcg.longest_path()
                vuls[i][Global.KEY_GLOBAL_LONGEST_FCG_PATH] = len(path)

                # parse AST
                self.stats.setProj(testcase_outpath, testsuite=self.testsuite)
                # generate options
                the_options = ['-I'+Global.FAKE_LIBC_INCLUDE, '-I'+testcase_outpath, '-DINCLUDEMAIN']
                for the_parent, the_dirs, the_filenames in os.walk(testcase_outpath):
                    for the_dir in the_dirs:
                        the_options.append('-I'+os.path.abspath(os.path.join(the_parent, the_dir)))
                if parser == 'pycparser':
                    self.stats.setOptions(the_options)
                    result = self.stats.global_stats()
                elif parser == 'clang':
                    self.stats.setOptions(the_options[1:])
                    result = self.stats.global_stats2()
                vuls[i][Global.KEY_GLOBAL_IF_NUM] = result[Global.KEY_GLOBAL_IF_NUM]
                vuls[i][Global.KEY_GLOBAL_IF_DEPTH] = result[Global.KEY_GLOBAL_IF_DEPTH]
                vuls[i][Global.KEY_GLOBAL_FOR_NUM] = result[Global.KEY_GLOBAL_FOR_NUM]
                vuls[i][Global.KEY_GLOBAL_FOR_DEPTH] = result[Global.KEY_GLOBAL_FOR_DEPTH]
                vuls[i][Global.KEY_GLOBAL_WHILE_NUM] = result[Global.KEY_GLOBAL_WHILE_NUM]
                vuls[i][Global.KEY_GLOBAL_WHILE_DEPTH] = result[Global.KEY_GLOBAL_WHILE_DEPTH]
                vuls[i][Global.KEY_GLOBAL_SWITCH_NUM] = result[Global.KEY_GLOBAL_SWITCH_NUM]
                vuls[i][Global.KEY_GLOBAL_SWITCH_DEPTH] = result[Global.KEY_GLOBAL_SWITCH_DEPTH]
                vuls[i][Global.KEY_GLOBAL_GOTO_NUM] = result[Global.KEY_GLOBAL_GOTO_NUM]
                vuls[i][Global.KEY_GLOBAL_ARRDECL_NUM] = result[Global.KEY_GLOBAL_ARRDECL_NUM]
                vuls[i][Global.KEY_GLOBAL_ARRDECL_DIMEN] = result[Global.KEY_GLOBAL_ARRDECL_DIMEN]
                vuls[i][Global.KEY_GLOBAL_ARRREF_NUM] = result[Global.KEY_GLOBAL_ARRREF_NUM]
                vuls[i][Global.KEY_GLOBAL_ARRREF_DIMEN] = result[Global.KEY_GLOBAL_ARRREF_DIMEN]
                vuls[i][Global.KEY_GLOBAL_EXTERN_NUM] = result[Global.KEY_GLOBAL_EXTERN_NUM]
                vuls[i][Global.KEY_GLOBAL_STRUCTREF_NUM] = result[Global.KEY_GLOBAL_STRUCTREF_NUM]
                vuls[i][Global.KEY_GLOBAL_STRUCTREF_DEPTH] = result[Global.KEY_GLOBAL_STRUCTREF_DEPTH]
                vuls[i][Global.KEY_GLOBAL_PTRREF_NUM] = result[Global.KEY_GLOBAL_PTRREF_NUM]
                vuls[i][Global.KEY_GLOBAL_PTRREF_DEPTH] = result[Global.KEY_GLOBAL_PTRREF_DEPTH]
                vuls[i][Global.KEY_GLOBAL_FUNCPTR_NUM] = result[Global.KEY_GLOBAL_FUNCPTR_NUM]

                #############################################
                # parse additional info and counterexamples #
                #############################################
                counterexamples = {}
                if self.testsuite == "juliet":
                    infos = Juliet_parser.parse_juliet_vul_info(testcase_outpath)
                    for info in infos:
                        sig = info['signature'] #bad, goodG2B, goodB2G, goodG2B1, goodG2B2, ...
                        line = info['line']
                        filename = info['filename']
                        if sig.startswith("bad"):
                            vuls[i][Global.KEY_VUL_LOCATION] = vuls[i][Global.KEY_VUL_LOCATION] + "#" + filename + ":" + line
                        if sig.startswith("good") and info['isvul'] == 0:
                            if sig not in counterexamples.keys():
                                counterexamples[sig] = self.clone(vuls[i])
                                counterexamples[sig][Global.KEY_VUL_LOCATION] = filename + ":" + line
                                counterexamples[sig][Global.KEY_ISVUL] = False
                            else:
                                counterexamples[sig][Global.KEY_VUL_LOCATION] += "#" + filename + ":" + line

                if self.testsuite == "juliet":
                    vuls[i][Global.KEY_VUL_LOCATION] = vuls[i][Global.KEY_VUL_LOCATION].strip('#')
                    for sig in counterexamples:
                        add_vuls.append(counterexamples[sig])

            ########################################################################
            # add additional vuls (counterexamples parsed from juliet test suites) #
            ########################################################################
            for vul in add_vuls:
                vuls.append(vul)
            # 删去xml中存在，但实际不存在的测试用例
            removed_vuls = []
            for vul in vuls:
                if Global.KEY_TESTCASE_DIR not in vul.keys():
                    removed_vuls.append(vul)
            for vul in removed_vuls:
                vuls.remove(vul)

            #######################################
            # create 1-hot vectors for taint sink #
            #######################################
            for i in range(0, len(vuls)):
                testcase_outpath = vuls[i][Global.KEY_TESTCASE_DIR]
                self.stats.setProj(testcase_outpath, testsuite)
                vul_locs = vuls[i][Global.KEY_VUL_LOCATION].split('#')
                word_vector = [] # store features in every vul_loc of a vulnerability
                for vul_loc in vul_locs:
                    tmp = vul_loc.split(':')
                    if len(tmp) >=2:
                        vectors = self.stats.gen_word_vector(tmp[0], tmp[1]) # filename and line
                        for word in vectors: # for a vulnerability, put the words from all tags into the same vector
                            if word not in word_vector:
                                word_vector.append(word)
                    else:
                        print("skip one_hot_vectors")
                word_vector.sort()
                vuls[i][Global.KEY_ONEHOT_VECTOR] = word_vector

            ################################################################
            # for each vulnerability, parse the related syntactic features #
            ################################################################
            for i in range(len(vuls)):
                vul_location = vuls[i][Global.KEY_VUL_LOCATION]
                print(vul_location)
                # 先把所有函数的起止行号拿到
                infos = []
                testcase_outpath = vuls[i][Global.KEY_TESTCASE_DIR]
                appendix = ['.c', '.cpp', '.cc']
                for parent, dirs, filenames in os.walk(testcase_outpath):
                    for f in filenames:
                        if os.path.splitext(f)[-1] not in appendix:
                            continue
                        raw_info = Juliet_parser.gen_func_info(os.path.join(parent, f))
                        info = Juliet_parser.parse_func_info(raw_info, filters=[testcase_outpath])
                        if info == {}:
                            continue
                        infos.append(info)
                # 获取漏洞相关函数(目前只是在函数调用图中，所有以main为root节点的函数)
                self.fcg.setProj(testcase_outpath)
                print(testcase_outpath)
                self.fcg.gen_fcg()
                related_funcs = self.fcg.get_related_funcs(vul_location, other_func="main")
                # 获取漏洞相关函数的起止行号
                related_funcs_info = []
                for funcs in related_funcs:
                    found = False
                    for info in infos:
                        if found:
                            break
                        for filename in info.keys():
                            if found:
                                break
                            for funcname in info[filename].keys():
                                if found:
                                    break
                                if funcs == funcname:
                                    # 函数名，文件名，起始行，结束行。四元组，都是字符串
                                    related_funcs_info.append((funcs, filename, info[filename][funcname]["funcstartline"], info[filename][funcname]["funcendline"]))
                                    found = True

                # 使用clang解析漏洞相关函数的语法特征
                self.stats.setProj(testcase_outpath, testsuite=self.testsuite)
                self.stats.related_funcs_info = related_funcs_info
                result = self.stats.global_stats2(filteration=True)
                vuls[i][Global.KEY_IF_NUM] = result[Global.KEY_IF_NUM]
                vuls[i][Global.KEY_IF_DEPTH] = result[Global.KEY_IF_DEPTH]
                vuls[i][Global.KEY_FOR_NUM] = result[Global.KEY_FOR_NUM]
                vuls[i][Global.KEY_FOR_DEPTH] = result[Global.KEY_FOR_DEPTH]
                vuls[i][Global.KEY_WHILE_NUM] = result[Global.KEY_WHILE_NUM]
                vuls[i][Global.KEY_WHILE_DEPTH] = result[Global.KEY_WHILE_DEPTH]
                vuls[i][Global.KEY_SWITCH_NUM] = result[Global.KEY_SWITCH_NUM]
                vuls[i][Global.KEY_SWITCH_DEPTH] = result[Global.KEY_SWITCH_DEPTH]
                vuls[i][Global.KEY_GOTO_NUM] = result[Global.KEY_GOTO_NUM]
                vuls[i][Global.KEY_ARRDECL_NUM] = result[Global.KEY_ARRDECL_NUM]
                vuls[i][Global.KEY_ARRDECL_DIMEN] = result[Global.KEY_ARRDECL_DIMEN]
                vuls[i][Global.KEY_ARRREF_NUM] = result[Global.KEY_ARRREF_NUM]
                vuls[i][Global.KEY_ARRREF_DIMEN] = result[Global.KEY_ARRREF_DIMEN]
                vuls[i][Global.KEY_EXTERN_NUM] = result[Global.KEY_EXTERN_NUM]
                vuls[i][Global.KEY_STRUCTREF_NUM] = result[Global.KEY_STRUCTREF_NUM]
                vuls[i][Global.KEY_STRUCTREF_DEPTH] = result[Global.KEY_STRUCTREF_DEPTH]
                vuls[i][Global.KEY_PTRREF_NUM] = result[Global.KEY_PTRREF_NUM]
                vuls[i][Global.KEY_PTRREF_DEPTH] = result[Global.KEY_PTRREF_DEPTH]
                vuls[i][Global.KEY_FUNCPTR_NUM] = result[Global.KEY_FUNCPTR_NUM]
                vuls[i][Global.KEY_LONGEST_FCG_PATH] = len(self.fcg.related_longest)
                print(vuls[i])

            for vul in vuls:
                final_vuls.append(vul)


            ######################
            # Write result to db #
            ######################
            print("Writing to db...")
            self.dao.connect()
            for vul in vuls:
                _id = vul[Global.KEY_TESTCASE_ID]
                _language = Global.LANGUAGE    # input by hand
                _file_num = vul[Global.KEY_FILE_NUM]
                _loc = vul[Global.KEY_LOC]
                _func_num = vul[Global.KEY_FUNC_NUM]
                _isvul = vul[Global.KEY_ISVUL]
                _vultype = vul[Global.KEY_VUL_TYPE]
                _vullocation = vul[Global.KEY_VUL_LOCATION]
                _global_if_num = vul[Global.KEY_GLOBAL_IF_NUM]
                _global_if_depth = vul[Global.KEY_GLOBAL_IF_DEPTH]
                _global_for_num = vul[Global.KEY_GLOBAL_FOR_NUM]
                _global_for_depth = vul[Global.KEY_GLOBAL_FOR_DEPTH]
                _global_while_num = vul[Global.KEY_GLOBAL_WHILE_NUM]
                _global_while_depth = vul[Global.KEY_GLOBAL_WHILE_DEPTH]
                _global_switch_num = vul[Global.KEY_GLOBAL_SWITCH_NUM]
                _global_switch_depth = vul[Global.KEY_GLOBAL_SWITCH_DEPTH]
                _global_goto_num = vul[Global.KEY_GLOBAL_GOTO_NUM]
                _global_arrdecl_num = vul[Global.KEY_GLOBAL_ARRDECL_NUM]
                _global_arrdecl_dimen = vul[Global.KEY_GLOBAL_ARRDECL_DIMEN]
                _global_arrref_num = vul[Global.KEY_GLOBAL_ARRREF_NUM]
                _global_arrref_dimen = vul[Global.KEY_GLOBAL_ARRREF_DIMEN]
                _global_longest_fcg = vul[Global.KEY_GLOBAL_LONGEST_FCG_PATH]
                _global_extern_num = vul[Global.KEY_GLOBAL_EXTERN_NUM]
                _global_structref_num = vul[Global.KEY_GLOBAL_STRUCTREF_NUM]
                _global_structref_depth = vul[Global.KEY_GLOBAL_STRUCTREF_DEPTH]
                _global_ptrref_num = vul[Global.KEY_GLOBAL_PTRREF_NUM]
                _global_ptrref_depth = vul[Global.KEY_GLOBAL_PTRREF_DEPTH]
                _global_funcptr_num = vul[Global.KEY_GLOBAL_FUNCPTR_NUM]

                _if_num = vul[Global.KEY_IF_NUM]
                _if_depth = vul[Global.KEY_IF_DEPTH]
                _for_num = vul[Global.KEY_FOR_NUM]
                _for_depth = vul[Global.KEY_FOR_DEPTH]
                _while_num = vul[Global.KEY_WHILE_NUM]
                _while_depth = vul[Global.KEY_WHILE_DEPTH]
                _switch_num = vul[Global.KEY_SWITCH_NUM]
                _switch_depth = vul[Global.KEY_SWITCH_DEPTH]
                _goto_num = vul[Global.KEY_GOTO_NUM]
                _arrdecl_num = vul[Global.KEY_ARRDECL_NUM]
                _arrdecl_dimen = vul[Global.KEY_ARRDECL_DIMEN]
                _arrref_num = vul[Global.KEY_ARRREF_NUM]
                _arrref_dimen = vul[Global.KEY_ARRREF_DIMEN]
                _longest_fcg = vul[Global.KEY_LONGEST_FCG_PATH]
                _extern_num = vul[Global.KEY_EXTERN_NUM]
                _structref_num = vul[Global.KEY_STRUCTREF_NUM]
                _structref_depth = vul[Global.KEY_STRUCTREF_DEPTH]
                _ptrref_num = vul[Global.KEY_PTRREF_NUM]
                _ptrref_depth = vul[Global.KEY_PTRREF_DEPTH]
                _funcptr_num = vul[Global.KEY_FUNCPTR_NUM]

                _onehot_vector = str(vul[Global.KEY_ONEHOT_VECTOR])

                self.dao.lock.acquire()
                sql_str_query = "select _id from neueval_testcases where vul_location='%s'" %(self.dao.conn.escape_string(_vullocation))
                print(sql_str_query)
                _ids = ()
                try:
                    self.dao.cursor.execute(sql_str_query)
                    _ids = self.dao.cursor.fetchall()
                except Exception as e:
                    print('error querying info')
                    print(e)
                finally:
                    self.dao.lock.release()
                if len(_ids) > 0:
                    for _id in _ids:
                        _id, = _id
                        sql_str_update = "update neueval_testcases set global_if_num=%d, if_num=%d, global_if_depth=%d, if_depth=%d, global_for_num=%d, for_num=%d, global_for_depth=%d, for_depth=%d, global_while_num=%d, while_num=%d, global_while_depth=%d, while_depth=%d, global_switch_num=%d, switch_num=%d, global_switch_depth=%d, switch_depth=%d, global_goto_num=%d, goto_num=%d, global_arrdecl_num=%d, arrdecl_num=%d, global_arrdecl_dimen=%d, arrdecl_dimen=%d, global_arrref_num=%d, arrref_num=%d, global_arrref_dimen=%d, arrref_dimen=%d, global_longest_fcg=%d, longest_fcg=%d, global_extern_num=%d, extern_num=%d, global_structref_num=%d, structref_num=%d, global_structref_depth=%d, structref_depth=%d, global_ptrref_num=%d, ptrref_num=%d, global_ptrref_depth=%d, ptrref_depth=%d, global_funcptr_num=%d, funcptr_num=%d where _id=%d" %(_global_if_num, _if_num, _global_if_depth, _if_depth, _global_for_num, _for_num, _global_for_depth, _for_depth, _global_while_num, _while_num, _global_while_depth, _while_depth, _global_switch_num, _switch_num, _global_switch_depth, _switch_depth, _global_goto_num, _goto_num, _global_arrdecl_num, _arrdecl_num, _global_arrdecl_dimen, _arrdecl_dimen, _global_arrref_num, _arrref_num, _global_arrref_dimen, _arrref_dimen, _global_longest_fcg, _longest_fcg, _global_extern_num, _extern_num, _global_structref_num, _structref_num, _global_structref_depth, _structref_depth, _global_ptrref_num, _ptrref_num, _global_ptrref_depth, _ptrref_depth, _global_funcptr_num, _funcptr_num, _id)
                        print(sql_str_update)
                        self.dao.lock.acquire()
                        try:
                            self.dao.cursor.execute(sql_str_update)
                        except Exception as e:
                            print('error updating info')
                            print(e)
                        finally:
                            self.dao.lock.release()
                else:            
                    sql_str = "INSERT INTO neueval_testcases set testcase_id='%s', language='%s', file_num=%d, lines_of_code=%d, func_num=%d, is_vul=%d, vul_type='%s', vul_location='%s', global_if_num=%d, if_num=%d, global_if_depth=%d, if_depth=%d, global_for_num=%d, for_num=%d, global_for_depth=%d, for_depth=%d, global_while_num=%d, while_num=%d, global_while_depth=%d, while_depth=%d, global_switch_num=%d, switch_num=%d, global_switch_depth=%d, switch_depth=%d, global_goto_num=%d, goto_num=%d, global_arrdecl_num=%d, arrdecl_num=%d, global_arrdecl_dimen=%d, arrdecl_dimen=%d, global_arrref_num=%d, arrref_num=%d, global_arrref_dimen=%d, arrref_dimen=%d, global_longest_fcg=%d, longest_fcg=%d, global_extern_num=%d, extern_num=%d, global_structref_num=%d, structref_num=%d, global_structref_depth=%d, structref_depth=%d, global_ptrref_num=%d, ptrref_num=%d, global_ptrref_depth=%d, ptrref_depth=%d, global_funcptr_num=%d, funcptr_num=%d, onehot_vector='%s'" %(_id, _language, _file_num, _loc, _func_num, _isvul, _vultype, self.dao.conn.escape_string(_vullocation), _global_if_num, _if_num, _global_if_depth, _if_depth, _global_for_num, _for_num, _global_for_depth, _for_depth, _global_while_num, _while_num, _global_while_depth, _while_depth, _global_switch_num, _switch_num, _global_switch_depth, _switch_depth, _global_goto_num, _goto_num, _global_arrdecl_num, _arrdecl_num, _global_arrdecl_dimen, _arrdecl_dimen, _global_arrref_num, _arrref_num, _global_arrref_dimen, _arrref_dimen, _global_longest_fcg, _longest_fcg, _global_extern_num, _extern_num, _global_structref_num, _structref_num, _global_structref_depth, _structref_depth, _global_ptrref_num, _ptrref_num, _global_ptrref_depth, _ptrref_depth, _global_funcptr_num, _funcptr_num, self.dao.conn.escape_string(_onehot_vector))
                    print(sql_str)
                    self.dao.lock.acquire()
                    try:
                        self.dao.cursor.execute(sql_str)
                        print(sql_str)
                    except Exception as e:
                        print('error inserting info')
                        print(e)
                    finally:
                        self.dao.lock.release()
            self.dao.conn.commit()
            # ends: for vuls in divided_vuls

        self.dao.disconnect()
        self.vuls = final_vuls

    def __parseSARD88Manifest2(self, manifest, testsuite):
        pattern_bad = '/\*\s*[bB][aA][dD]\s*\*/'
        pattern_fix = '/\*\s*[oO][kK]\s*\*/'
        re_bad = re.compile(pattern_bad)
        re_fix = re.compile(pattern_fix)
        vuls = []
        indir = os.path.dirname(manifest)
        for event, elem in ET.iterparse(manifest, events=('end', 'end-ns')):
            if event == 'end' or event == 'end-ns':
                if elem.tag == 'testcase':
                    _id = '00' + elem.attrib['id']
                    # find vul_location
                    testcase_origpath = os.path.join(indir, 'testcases/000/')
                    testcase_origpath = os.path.join(testcase_origpath, _id[:3])
                    testcase_origpath = os.path.join(testcase_origpath, _id[3:])
                    for parent, dirs, files in os.walk(testcase_origpath):
                        for f in files:
                            if os.path.splitext(f)[1] == '.c':
                                fp = open(os.path.join(parent, f))
                                lines = fp.readlines()
                                for i in range(0, len(lines)):
                                    line = lines[i].strip()
                                    if re_bad.fullmatch(line): # its a bug
                                        vul = {}
                                        vul[Global.KEY_TESTCASE_ID] = testsuite + '_' + _id
                                        vul[Global.KEY_ISVUL] = 1
                                        vul[Global.KEY_VUL_TYPE] = 'CWE119'
                                        vul[Global.KEY_VUL_LOCATION] = os.path.basename(f) + ':' + str(i+1+1)
                                        vuls.append(vul)
                                    elif re_fix.fullmatch(line): # its a counterexample
                                        vul = {}
                                        vul[Global.KEY_TESTCASE_ID] = testsuite + '_' + _id
                                        vul[Global.KEY_ISVUL] = 0
                                        vul[Global.KEY_VUL_TYPE] = 'CWE119'
                                        vul[Global.KEY_VUL_LOCATION] = os.path.basename(f) + ':' + str(i+1+1)
                                        vuls.append(vul)
                                    else:
                                        continue
                                fp.close()
        return vuls


    def __parseSARD88Manifest(self, f, testsuite):
        vuls = []
        for event, elem in ET.iterparse(f, events=('end', 'end-ns')):
            if event == 'end' or event == 'end-ns':
                if elem.tag == 'testcase':
                    _id = '00' + elem.attrib['id']
                    for child in elem:
                        if child.tag == 'description':
                            _file = ""
                            is_vul = -1
                            description_txt = child.text
                            # find file name
                            pos = description_txt.find("Bad file:")
                            if pos < 0:
                                is_vul = 0
                                pos = description_txt.find("Patched file:")
                                pos = pos + len("Patched file:")
                            else:
                                is_vul = 1
                                pos = pos + len("Bad file:")
                            last_pos = description_txt.find("<br>", pos)
                            _file = description_txt[pos : last_pos].strip()
                            # find line number
                            pos = description_txt.find("Bad line number:")
                            if pos < 0:
                                pos = description_txt.find("Bad line numbers:")
                                if pos < 0:
                                    pos = description_txt.find("Patched line number:")
                                    if pos < 0:
                                        pos = description_txt.find("Patched line numbers:")
                                        pos = pos + len("Patched line numbers:")
                                    else:
                                        pos = pos + len("Patched line number:")
                                else:
                                    pos = pos + len("Bad line numbers:")
                            else:
                                pos = pos + len("Bad line number:")
                            if pos >= 0:
                                last_pos = description_txt.find("<br>", pos)
                                line_number = description_txt[pos : last_pos].strip()
                                for line in line_number.split(','):
                                    line = line.strip()
                                    vul = {}
                                    vul[Global.KEY_TESTCASE_ID] = testsuite + '_' + _id
                                    vul[Global.KEY_ISVUL] = is_vul
                                    vul[Global.KEY_VUL_TYPE] = 'CWE119'
                                    vul[Global.KEY_VUL_LOCATION] = _file + ':' + line
                                    vuls.append(vul)
        return vuls


    def __parseSARD100Manifest(self, f, testsuite):
        vuls = []
        for event, elem in ET.iterparse(f, events=('end', 'end-ns')):
            if event == 'end' or event == 'end-ns':
                tag = elem.tag
                if tag == 'testcase':
                    _id = elem.attrib['id']
                    for child in elem:
                        if child.tag == 'file':
                            _file = child.attrib['path']
                            spliter = _id[0:3]+"/"+_id[3:]
                            _file = _id + _file.split(spliter)[-1]
                            for child2 in child:
                                if child2.tag == 'fix' or child2.tag == 'flaw':
                                    vul = {}
                                    vul[Global.KEY_TESTCASE_ID] = testsuite + '_' + _id
                                    vul[Global.KEY_VUL_LOCATION] = _file+":"+child2.attrib['line']
                                    vul[Global.KEY_VUL_TYPE] = child2.attrib['name'].split(':')[0]
                                    if child2.tag == 'fix':
                                        vul[Global.KEY_ISVUL] = False
                                    else:
                                        vul[Global.KEY_ISVUL] = True
                                    vuls.append(vul)
        return vuls

    def __parseJulietManifest(self, f, cwe_list_filter=[]):
        vuls = []
        for event, elem in ET.iterparse(f, events=('end', 'end-ns')):
            if event == 'end' or event == 'end-ns':
                if elem.tag == 'file':
                    lst = []
                    for child in elem:
                        lst.append(child)
                    # <file> doesn't have child <flaw>, skip
                    if len(lst) <= 0:
                        continue
                    vul = {}
                    fpath = elem.get('path')

                    # cpp is not to be parsed, for now
                    if fpath.endswith('.cpp'):
                        continue

                    # vul type is not in white list, skip
                    if len(cwe_list_filter) > 0 and fpath.split('_')[0] not in cwe_list_filter:
                        continue
                    # extract signature (which is used as testcase id) from file name
                    base = os.path.basename(fpath)
                    part_2 = base.split("_")[-1]
                    if part_2.startswith("good") or part_2.startswith("bad"):
                        part_2 = base.split("_")[-2]
                    num = part_2[0:2]
                    signature = base.split("_"+num)[0] + "_" + num
                    for child in elem:
                        if child.tag == 'flaw':
                            vul = {}
                            vul[Global.KEY_TESTCASE_ID] = signature
                            # records in manifest are all vulnerabilities
                            vul[Global.KEY_ISVUL] = True
                            vul[Global.KEY_VUL_TYPE] = child.get('name').split(':')[0]
                            # parse vul location later
                            #vul[Global.KEY_VUL_LOCATION] = fpath+":"+child.get('line')
                            vul[Global.KEY_VUL_LOCATION] = ""
                            vuls.append(vul)
        return vuls

    def getLoc(self, sourcefile):
        cmd = ""
        if self.testsuite == "juliet":
        # 去除testcasesupport中的源代码文件
            file_lst = []
            if os.path.isdir(sourcefile):
                for parent, dirnames, fnames in os.walk(sourcefile):
                    for fname in fnames:
                        if fname in Global.JULIET_TESTCASESUPPORT:
                            continue
                        else:
                            file_lst.append(os.path.join(parent, fname))
            else:
                if sourcefile not in Global.JULIET_TESTCASESUPPORT:
                    file_lst.append(sourcefile)
            cmd += 'cloc --json'
            for f in file_lst:
                cmd += ' ' + f
        else:
            cmd = 'cloc --json %s'%(sourcefile)
        p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)
        content = p.stdout.read()
        j = json.loads(content)
        file_num = j['SUM']['nFiles']
        loc = j['SUM']['code']
        return file_num, loc

    def countFuncnum2(self, testcase_dir, appendix=['.c', '.cpp']):
        testcase_dir = os.path.abspath(testcase_dir)
        print("testcase_dir: " + testcase_dir)
        infos = []
        for parent, dirs, filenames in os.walk(testcase_dir):
            for f in filenames:
                if os.path.splitext(f)[-1] not in appendix:
                    continue
                raw_info = Juliet_parser.gen_func_info(os.path.join(parent, f))
                info = Juliet_parser.parse_func_info(raw_info, filters=[testcase_dir])
                if info == {}:
                    continue
                infos.append(info)
        func_num, file_func_map = 0, {}
        for info in infos:
            for file_name in info.keys():
                if file_name not in file_func_map.keys():
                    file_func_map[file_name] = []
                for func_name in info[file_name].keys():
                    file_func_map[file_name].append(func_name)
                    func_num = func_num + 1
        return func_num, file_func_map

    def countFuncnum(self, testcase_dir, appendix='c', wllvm=False):
        CC = 'clang'
        if appendix != 'c':
            CC = 'clang++'
        if not wllvm:
            cmd = 'cd %s; %s -S -DINCLUDEMAIN -emit-llvm *.%s' %(testcase_dir, CC, appendix)
            os.system(cmd)
        else:
            # To be implemented to generate .ll .bc for big project
            pass
        
        # run opt
        total_func = 0
        file_func_map = {} # key is filename, value is functions defined in this file
        for parent, dirs, filenames in os.walk(testcase_dir):
            for f in filenames:
                if f.endswith('.ll') or f.endswith('.bc'):
                    cmd = '%s -load %s -hello2 -stats < %s > /dev/null' %(Config.OPT, os.path.join(Config.LIBS, 'LLVMHello.so'), os.path.join(parent, f))
                    p = subprocess.Popen(cmd, shell=True, stderr=subprocess.PIPE)
                    content = p.stderr.read()
                    content = bytes.decode(content)
                    content = content.strip().split('\n')
                    ### get func name, store into file_func_map
                    ### get func_num, store into total_func
                    with open(os.path.join(parent, f)) as fp:
                        lines = fp.readlines()
                        for l in lines:
                            if l.startswith('source_filename = '):
                                fname = l.split('source_filename = ')[-1].strip().strip('\"')
                                file_func_map[fname] = []
                                for line in content:
                                    line = line.strip()
                                    if line.startswith('Hello:'):
                                        func_name = line.split(': ')[-1]
                                        file_func_map[fname].append(func_name)
                                    elif line.endswith('Counts number of functions greeted'):
                                        func_num = int(line.split(' ')[0])
                                        total_func += func_num
                                break
        # delete ll or bc file
        for parent, dirs, filenames in os.walk(testcase_dir):
            for f in filenames:
                if f.endswith('.ll') or f.endswith('.bc'):
                    cmd = 'rm -f %s'%(os.path.join(parent, f))
                    os.system(cmd)

        return total_func, file_func_map


    def clone(self, vul):
        new_vul = {}
        for key in vul.keys():
            new_vul[key] = vul[key]
        return new_vul


    def update_vul_sink(self, testsuite='juliet', CWE='CWE369'):
        sql_str = "select _id, testcase_id, vul_location from neueval_testcases where testcase_id like "
        if testsuite == 'juliet':
            sql_str = sql_str + "'%s%%'" %(CWE)
        else:
            sql_str = sql_str + "'%s%%'" %(testsuite)
        self.dao.connect()
        self.dao.cursor.execute(sql_str)
        results = self.dao.cursor.fetchall()
        for one in results:
            testcase_dir = Config.TESTSUITE
            testcase_id = one[1]
            if testsuite == 'juliet':
                testcase_dir = testcase_dir + '/' + 'juliet_%s' %(CWE.lower()) + '/' + testcase_id.split('__')[0] + '/' + testcase_id
            elif testsuite == 'sard100' or testsuite == 'sard101' or testsuite == 'sard88':
                testcase_dir = testcase_dir + '/%s/' %(testsuite) + testcase_id
            else:
                pass
            locations = one[2]
            location_str = {}
            location_str['location'] = []
            for location in locations.split('#'):
                f = location.split(':')[0]
                line = location.split(':')[1]
                f = os.path.join(testcase_dir, os.path.basename(f))
                with open(f, 'rb') as fp:
                    content = fp.read()
                    content = content.decode('utf-8', 'ignore')
                    lines = content.split('\n')
                    location_str['location'].append(lines[int(line)-1].strip())
            location_str = json.dumps(location_str)
            print(location_str)
            sql_str2 = "update neueval_testcases set vul_sink_raw='%s' where _id=%d" %(self.dao.conn.escape_string(location_str), one[0])
            self.dao.cursor.execute(sql_str2)
        self.dao.conn.commit()
        self.dao.disconnect()



if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--action', '-a', help='Action to be performed, action could be: "parse", "copy", "update"')
    parser.add_argument('--input', '-i', help='Input path')
    parser.add_argument('--output', '-o', help='Output path')
    parser.add_argument('--benchmark', '-b', help='Name of input benchmark, which could be: "juliet", "sard100", "sard101", "sard88"')
    parser.add_argument('--cwelist', '-l', help='White list of CWE IDs, use space to seprate them, e.g., -l "CWE121 CWE120"')
    parser.add_argument('--parser', '-p', help='Parser engines, which could be: "pycparser", "clang"')

    args = parser.parse_args()
    util_action = args.action
    util = Util()
    if util_action == 'parse':
        cwe_list = []
        if args.cwelist:
            cwe_list = args.cwelist.split(' ')
        util.copyAndParse(indir=args.input, outdir=args.output, testsuite=args.benchmark, cwe_list=cwe_list, parser=args.parser)
    if util_action == 'copy':
        cwe_list = []
        if args.cwelist:
            cwe_list = args.cwelist.split(' ')
        util.copy(indir=args.input, outdir=args.output, testsuite=args.benchmark, cwe_list=cwe_list)
    if util_action == 'update':
        util.update_vul_sink(testsuite=args.benchmark, CWE=args.cwelist)
